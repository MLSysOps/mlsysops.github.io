"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1130],{3905:(e,t,r)=>{r.d(t,{Zo:()=>c,kt:()=>y});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function o(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function p(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=n.createContext({}),l=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):o(o({},t),e)),r},c=function(e){var t=l(e.components);return n.createElement(s.Provider,{value:t},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},f=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,c=p(e,["components","mdxType","originalType","parentName"]),m=l(r),f=a,y=m["".concat(s,".").concat(f)]||m[f]||u[f]||i;return r?n.createElement(y,o(o({ref:t},c),{},{components:r})):n.createElement(y,o({ref:t},c))}));function y(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=r.length,o=new Array(i);o[0]=f;var p={};for(var s in t)hasOwnProperty.call(t,s)&&(p[s]=t[s]);p.originalType=e,p[m]="string"==typeof e?e:a,o[1]=p;for(var l=2;l<i;l++)o[l]=r[l];return n.createElement.apply(null,o)}return n.createElement.apply(null,r)}f.displayName="MDXCreateElement"},4132:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>p,toc:()=>l});var n=r(7462),a=(r(7294),r(3905));const i={},o="Deep Reinforcement Learning System",p={unversionedId:"paper/Specific System/drl_system",id:"paper/Specific System/drl_system",title:"Deep Reinforcement Learning System",description:"For now, this category only contains system for drl papers and projects.",source:"@site/docs/paper/Specific System/drl_system.md",sourceDirName:"paper/Specific System",slug:"/paper/Specific System/drl_system",permalink:"/docs/paper/Specific System/drl_system",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/paper/Specific System/drl_system.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"System for GNN training&inference",permalink:"/docs/paper/Specific System/GNN_system"},next:{title:"Edge or Mobile Papers",permalink:"/docs/paper/Specific System/edge_system"}},s={},l=[],c={toc:l};function m(e){let{components:t,...r}=e;return(0,a.kt)("wrapper",(0,n.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"deep-reinforcement-learning-system"},"Deep Reinforcement Learning System"),(0,a.kt)("p",null," For now, this category only contains system for drl papers and projects."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},'Mao, Hongzi, et al. "Park: An Open Platform for Learning-Augmented Computer Systems." Advances in Neural Information Processing Systems. 2019.'),(0,a.kt)("li",{parentName:"ul"},"Summary: This work builds a platform to introduce DRL to computer system optimizaton. It provides a lot of APIs so researcher can focus on developing algorithm rather spend a lot of time on writing system engineering codes."),(0,a.kt)("li",{parentName:"ul"},"Ray: A Distributed Framework for Emerging {AI} Applications ",(0,a.kt)("a",{parentName:"li",href:"https://www.usenix.org/conference/osdi18/presentation/moritz"},"[GitHub]"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Moritz, Philipp, et al. (",(0,a.kt)("em",{parentName:"li"},"OSDI 2018"),")"),(0,a.kt)("li",{parentName:"ul"},"Summary: Distributed DRL training, simulation and inference system. Can be used as a high-performance python framework."))),(0,a.kt)("li",{parentName:"ul"},"Elf: An extensive, lightweight and flexible research platform for real-time strategy games ",(0,a.kt)("a",{parentName:"li",href:"https://papers.nips.cc/paper/6859-elf-an-extensive-lightweight-and-flexible-research-platform-for-real-time-strategy-games.pdf"},"[Paper]")," ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/ELF"},"[GitHub]"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Tian, Yuandong, Qucheng Gong, Wenling Shang, Yuxin Wu, and C. Lawrence Zitnick. (",(0,a.kt)("em",{parentName:"li"},"NIPS 2017"),")"),(0,a.kt)("li",{parentName:"ul"},"Summary:"))),(0,a.kt)("li",{parentName:"ul"},"Horizon: Facebook's Open Source Applied Reinforcement Learning Platform ",(0,a.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/1811.00260"},"[Paper]")," ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/facebookresearch/Horizon"},"[GitHub]"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Gauci, Jason, et al. (",(0,a.kt)("em",{parentName:"li"},"preprint 2019"),")"))),(0,a.kt)("li",{parentName:"ul"},"RLgraph: Modular Computation Graphs for Deep Reinforcement Learning ",(0,a.kt)("a",{parentName:"li",href:"http://www.sysml.cc/doc/2019/43.pdf"},"[Paper]"),(0,a.kt)("a",{parentName:"li",href:"https://github.com/rlgraph/rlgraph"},"[GitHub]"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},"Schaarschmidt, Michael, Sven Mika, Kai Fricke, and Eiko Yoneki. (",(0,a.kt)("em",{parentName:"li"},"SysML 2019"),")"),(0,a.kt)("li",{parentName:"ul"},"Summary:")))))}m.isMDXComponent=!0}}]);