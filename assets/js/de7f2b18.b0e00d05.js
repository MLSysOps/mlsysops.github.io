"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[270],{3905:(e,a,t)=>{t.d(a,{Zo:()=>m,kt:()=>h});var i=t(7294);function r(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function n(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);a&&(i=i.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,i)}return t}function o(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?n(Object(t),!0).forEach((function(a){r(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):n(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function l(e,a){if(null==e)return{};var t,i,r=function(e,a){if(null==e)return{};var t,i,r={},n=Object.keys(e);for(i=0;i<n.length;i++)t=n[i],a.indexOf(t)>=0||(r[t]=e[t]);return r}(e,a);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(i=0;i<n.length;i++)t=n[i],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var p=i.createContext({}),s=function(e){var a=i.useContext(p),t=a;return e&&(t="function"==typeof e?e(a):o(o({},a),e)),t},m=function(e){var a=s(e.components);return i.createElement(p.Provider,{value:a},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var a=e.children;return i.createElement(i.Fragment,{},a)}},d=i.forwardRef((function(e,a){var t=e.components,r=e.mdxType,n=e.originalType,p=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),u=s(t),d=r,h=u["".concat(p,".").concat(d)]||u[d]||c[d]||n;return t?i.createElement(h,o(o({ref:a},m),{},{components:t})):i.createElement(h,o({ref:a},m))}));function h(e,a){var t=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var n=t.length,o=new Array(n);o[0]=d;var l={};for(var p in a)hasOwnProperty.call(a,p)&&(l[p]=a[p]);l.originalType=e,l[u]="string"==typeof e?e:r,o[1]=l;for(var s=2;s<n;s++)o[s]=t[s];return i.createElement.apply(null,o)}return i.createElement.apply(null,t)}d.displayName="MDXCreateElement"},7082:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>p,contentTitle:()=>o,default:()=>u,frontMatter:()=>n,metadata:()=>l,toc:()=>s});var i=t(7462),r=(t(7294),t(3905));const n={},o="Video System",l={unversionedId:"paper/Specific System/video_system",id:"paper/Specific System/video_system",title:"Video System",description:"Tools",source:"@site/docs/paper/Specific System/video_system.md",sourceDirName:"paper/Specific System",slug:"/paper/Specific System/video_system",permalink:"/docs/paper/Specific System/video_system",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/paper/Specific System/video_system.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Foundation Model Training/Serving System",permalink:"/docs/paper/Specific System/foundation_model"},next:{title:"Survey & Book",permalink:"/docs/paper/intro"}},p={},s=[{value:"Tools",id:"tools",level:2},{value:"Video Analysis Papers",id:"video-analysis-papers",level:2},{value:"Video Streaming Papers",id:"video-streaming-papers",level:2}],m={toc:s};function u(e){let{components:a,...t}=e;return(0,r.kt)("wrapper",(0,i.Z)({},m,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"video-system"},"Video System"),(0,r.kt)("h2",{id:"tools"},"Tools"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"VideoFlow: Python framework that facilitates the quick development of complex video analysis applications and other series-processing based applications in a multiprocessing environment. ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/videoflow/videoflow"},"[GitHub]")),(0,r.kt)("li",{parentName:"ul"},"VidGear: Powerful Multi-Threaded OpenCV and FFmpeg based Turbo Video Processing Python Library with unique State-of-the-Art Features. ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/abhiTronix/vidgear"},"[GitHub]")),(0,r.kt)("li",{parentName:"ul"},"NVIDIA DALI: A library containing both highly optimized building blocks and an execution engine for data pre-processing in deep learning applications ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/NVIDIA/DALI"},"[GitHub]")),(0,r.kt)("li",{parentName:"ul"},"TensorStream: A library for real-time video stream decoding to CUDA memory ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/Fonbet/argus-tensor-stream"},"[GitHub]")),(0,r.kt)("li",{parentName:"ul"},"C++ image processing library with using of SIMD: SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, AVX, AVX2, AVX-512, VMX(Altivec) ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/ermig1979/Simd"},"[GitHub]")),(0,r.kt)("li",{parentName:"ul"},"Pretrained image and video models for Pytorch. ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/alexandonian/pretorched-x"},"[GitHub]")),(0,r.kt)("li",{parentName:"ul"},"LiveDetect - Live video client to DeepDetect. ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/jolibrain/livedetect"},"[GitHub]"))),(0,r.kt)("h2",{id:"video-analysis-papers"},"Video Analysis Papers"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Server-Driven Video Streaming for Deep Learning Inference ",(0,r.kt)("a",{parentName:"li",href:"https://kuntaidu.github.io/assets/doc/DDS.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Kuntai Du, Ahsan Pervaiz, Xin Yuan, Aakanksha Chowdhery, Qizheng Zhang, Henry Hoffmann, Junchen Jiang (",(0,r.kt)("em",{parentName:"li"},"SIGCOMM2020"),")"))),(0,r.kt)("li",{parentName:"ul"},"Reducto: On-Camera Filtering for ResourceEfficient Real-Time Video Analytics ",(0,r.kt)("a",{parentName:"li",href:"http://web.cs.ucla.edu/~harryxu/papers/li-sigcomm20.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Yuanqi Li, Arthi Padmanabhan, Pengzhan Zhao, Yufei Wang, Guoqing Harry Xu, Ravi Netravali. (",(0,r.kt)("em",{parentName:"li"},"SIGCOMM2020"),")"))),(0,r.kt)("li",{parentName:"ul"},'Fu, Daniel Y., et al. "Rekall: Specifying video events using compositions of spatiotemporal labels." arXiv preprint arXiv:1910.02993 (2019). ',(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/1910.02993.pdf"},"[Paper]")),(0,r.kt)("li",{parentName:"ul"},"Puffer: Puffer is a Stanford University research study about using machine learning to improve video-streaming algorithms. Please visit ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/StanfordSNR/puffer"},"[GitHub]")),(0,r.kt)("li",{parentName:"ul"},"Visual Road: A Video Data Management Benchmark ",(0,r.kt)("a",{parentName:"li",href:"http://db.cs.washington.edu/projects/visualroad/"},"[Project Website]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Brandon Haynes, Amrita Mazumdar, Magdalena Balazinska, Luis Ceze, Alvin Cheung (",(0,r.kt)("em",{parentName:"li"},"SIGMOD 2019"),")"))),(0,r.kt)("li",{parentName:"ul"},"CaTDet: Cascaded Tracked Detector for Efficient Object Detection from Video ",(0,r.kt)("a",{parentName:"li",href:"http://www.sysml.cc/doc/2019/111.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Mao, Huizi, Taeyoung Kong, and William J. Dally. (",(0,r.kt)("em",{parentName:"li"},"SysML2019"),")"))),(0,r.kt)("li",{parentName:"ul"},"Live Video Analytics at Scale with Approximation and Delay-Tolerance ",(0,r.kt)("a",{parentName:"li",href:"https://www.microsoft.com/en-us/research/wp-content/uploads/2017/02/videostorm_nsdi17.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Zhang, Haoyu, Ganesh Ananthanarayanan, Peter Bodik, Matthai Philipose, Paramvir Bahl, and Michael J. Freedman. (",(0,r.kt)("em",{parentName:"li"},"NSDI 2017"),")"))),(0,r.kt)("li",{parentName:"ul"},"Chameleon: scalable adaptation of video analytics ",(0,r.kt)("a",{parentName:"li",href:"http://people.cs.uchicago.edu/~junchenj/docs/Chameleon_SIGCOMM_CameraReady.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Jiang, Junchen, et al. (",(0,r.kt)("em",{parentName:"li"},"SIGCOMM 2018"),")"),(0,r.kt)("li",{parentName:"ul"},"Summary: Configuration controller for balancing accuracy and resource. Golden configuration is a good design. Periodic profiling often exceeded any resource savings gained by adapting the configurations."))),(0,r.kt)("li",{parentName:"ul"},'Kang, Daniel, Peter Bailis, and Matei Zaharia. "Blazeit: Fast exploratory video queries using neural networks." arXiv preprint arXiv:1805.01046 (2018). ',(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/1805.01046.pdf"},"[Paper]")),(0,r.kt)("li",{parentName:"ul"},"Noscope: optimizing neural network queries over video at scale ",(0,r.kt)("a",{parentName:"li",href:"https://arxiv.org/pdf/1703.02529"},"[Paper]")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/stanford-futuredata/noscope"},"[GitHub]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Kang, Daniel, John Emmons, Firas Abuzaid, Peter Bailis, and Matei Zaharia. (",(0,r.kt)("em",{parentName:"li"},"VLDB2017"),")"),(0,r.kt)("li",{parentName:"ul"},"Summary: Information cache + difference detection model + small detection model + sequence optimizer"))),(0,r.kt)("li",{parentName:"ul"},"SVE: Distributed video processing at Facebook scale ",(0,r.kt)("a",{parentName:"li",href:"http://www.cs.princeton.edu/~wlloyd/papers/sve-sosp17.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Huang, Qi, et al. (",(0,r.kt)("em",{parentName:"li"},"SOSP2017"),")"))),(0,r.kt)("li",{parentName:"ul"},"Scanner: Efficient Video Analysis at Scale ",(0,r.kt)("a",{parentName:"li",href:"http://graphics.stanford.edu/papers/scanner/poms18_scanner.pdf"},"[Paper]"),(0,r.kt)("a",{parentName:"li",href:"https://github.com/scanner-research/scanner"},"[GitHub]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Poms, Alex, Will Crichton, Pat Hanrahan, and Kayvon Fatahalian (",(0,r.kt)("em",{parentName:"li"},"SIGGRAPH 2018"),")"))),(0,r.kt)("li",{parentName:"ul"},"A cloud-based large-scale distributed video analysis system ",(0,r.kt)("a",{parentName:"li",href:"https://ai.google/research/pubs/pub45631"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Wang, Yongzhe, et al. (",(0,r.kt)("em",{parentName:"li"},"ICIP 2016"),")"))),(0,r.kt)("li",{parentName:"ul"},"Rosetta: Large scale system for text detection and recognition in images ",(0,r.kt)("a",{parentName:"li",href:"https://research.fb.com/wp-content/uploads/2018/10/Rosetta-Large-scale-system-for-text-detection-and-recognition-in-images.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Borisyuk, Fedor, Albert Gordo, and Viswanath Sivakumar. (",(0,r.kt)("em",{parentName:"li"},"KDD 2018"),")")))),(0,r.kt)("h2",{id:"video-streaming-papers"},"Video Streaming Papers"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural-Enhanced Live Streaming: Improving Live Video Ingest via Online Learning ",(0,r.kt)("a",{parentName:"li",href:"http://ina.kaist.ac.kr/~livenas/livenas_sigcomm2020.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Jaehong Kim, Youngmok Jung, Hyunho Yeo, Juncheol Ye, and Dongsu Han (",(0,r.kt)("em",{parentName:"li"},"SIGCOMM2020"),")"))),(0,r.kt)("li",{parentName:"ul"},"Learning in situ: a randomized experiment in video streaming ",(0,r.kt)("a",{parentName:"li",href:"https://www.usenix.org/system/files/nsdi20-paper-yan.pdf"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Francis Y. Yan and Hudson Ayers, Stanford University; Chenzhi Zhu, Tsinghua University; Sadjad Fouladi, James Hong, Keyi Zhang, Philip Levis, and Keith Winstein, Stanford University (",(0,r.kt)("em",{parentName:"li"},"NSDI2020"),")"))),(0,r.kt)("li",{parentName:"ul"},"CSI: Inferring Mobile ABR Video Adaptation Behavior under HTTPS and QUIC ",(0,r.kt)("a",{parentName:"li",href:"https://dl.acm.org/doi/abs/10.1145/3342195.3387558"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Shichang Xu (University of Michigan), Subhabrata Sen (AT&T Labs Research), Z. Morley Mao (University of Michigan) (",(0,r.kt)("em",{parentName:"li"},"Eurosys2020"),")"))),(0,r.kt)("li",{parentName:"ul"},"Reconstructing proprietary video streaming algorithms ",(0,r.kt)("a",{parentName:"li",href:"https://www.usenix.org/conference/atc20/presentation/gruener"},"[Paper]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Maximilian Gr\xfcner, Melissa Licciardello, and Ankit Singla, ETH Z\xfcrich (",(0,r.kt)("em",{parentName:"li"},"ATC2020"),")"))),(0,r.kt)("li",{parentName:"ul"},"Neural adaptive content-aware internet video delivery. ",(0,r.kt)("a",{parentName:"li",href:"https://www.usenix.org/system/files/osdi18-yeo.pdf"},"[Paper]")," ",(0,r.kt)("a",{parentName:"li",href:"https://github.com/kaist-ina/NAS_public"},"[GitHub]"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Yeo, H., Jung, Y., Kim, J., Shin, J. and Han, D., 2018.  (",(0,r.kt)("em",{parentName:"li"},"OSDI 2018"),")"),(0,r.kt)("li",{parentName:"ul"},"Summary: Combine video super-resolution and ABR")))))}u.isMDXComponent=!0}}]);